场景：
要给100亿个数字排序，100亿个 int 型数字放在文件里面大概有 37.2GB，非常大，内存一次装不下了。
那么肯定是要拆分成小的文件一个一个来处理，最终在合并成一个排好序的大文件。
实现思路：
把大文件直接平均分成若干份，使得每一小份的大小足够放入内存，假设有1000份，然后对每一份小文件各自在内存中进行排序（可以用快速排序，归并排序，堆排序等等。）
1000份小文件内部排好序之后，就要把这些内部有序的小文件，合并成一个大的文件，可以用二叉堆来做1000路合并的操作，每个小文件是一路，合并后的大文件仍然有序。
具体过程：
首先遍历1000个文件，每个文件里面取第一个数字，组成 (数字, 文件号) 这样的组合加入到堆里（假设是从小到大排序，用小顶堆）
遍历完后堆里有1000个 (数字，文件号) ，这样的元素
然后不断从堆顶拿元素出来，每拿出一个元素，把它，然后去对应的文件里的文件号读取出来（这样可以做到小文件的随机访问），加一个元素进入堆，
直到那个文件被读取完。拿出来的元素当然追加到最终结果的文件里。
按照上面的操作，直到堆被取空了，此时最终结果文件里的全部数字就是有序的了。
扩展：
类似的100亿个数字求和，求中位数，求平均数，套路就是一样的了。
求中位数：在排序的基础上，遍历到中间的那个数就是中位数了。
求和：统计每个小文件的和，返回给master再求和就可以了。
求平均数：上面能求和了，再除以100亿就是平均数了。


